{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# AcF701 - SEC EDGAR Data Extraction 2\n",
    "by Dr Liang Jin\n",
    "\n",
    "- Step 1: access crawler.idx files from SEC EDGAR\n",
    "- Step 2: re-write crawler data to csv files\n",
    "- Step 3: retrieve 10K filing information including URLs\n",
    "- Step 4: extract text from html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup\n",
    "- import packages\n",
    "- Global variables (all in capital recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# define some global variables such as sample periods\n",
    "# Since 2005, SEC requires firms to disclosre \"Item 1A. Risk Factors\"\n",
    "BEG_YEAR = 2005\n",
    "END_YEAR = 2017\n",
    "\n",
    "# define working directories\n",
    "CWD = os.getcwd()\n",
    "# store re-formated index in csv\n",
    "INDEX_DIR = os.path.join(CWD, \"index/\")\n",
    "# store parsed page info in csv\n",
    "PAGE_DIR = os.path.join(CWD, \"page/\")\n",
    "# store collected form 10-k in html\n",
    "FORM_DIR = os.path.join(CWD, \"form/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# create directories if not exists yet\n",
    "dirs = [INDEX_DIR, PAGE_DIR, FORM_DIR]\n",
    "\n",
    "for d in dirs:\n",
    "    if not os.path.isdir(d):\n",
    "        os.mkdir(d)\n",
    "    print(\"{} exists\".format(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Some examples\n",
    "demo_index_urls = ['https://www.sec.gov/Archives/edgar/full-index/2016/QTR1/crawler.idx',\n",
    "                   'https://www.sec.gov/Archives/edgar/full-index/2016/QTR2/crawler.idx']\n",
    "demo_index_csv = INDEX_DIR + \"demo.csv\"\n",
    "demo_page_csv = PAGE_DIR + \"demo.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Previously...\n",
    "- function to get index URLs\n",
    "- function to re-write index data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create a list of urls pointing to individual crawler.idx files\n",
    "def getIndexURLs(start=2005, end=2017):\n",
    "    urls = []\n",
    "    for year in range(start, end+1):\n",
    "        for qtr in ['QTR1', 'QTR2', 'QTR3', 'QTR4']:\n",
    "            url = 'https://www.sec.gov/Archives/edgar/full-index/{}/{}/crawler.idx'.format(year, qtr)\n",
    "            urls.append(url)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Now we have a list of address, let's retrieve information from crawler.idx files\n",
    "# and rewrite the data to csv locally\n",
    "def writeIndexCSV(url, header_loc=7, firstrow_loc=9):\n",
    "    r = requests.get(url)\n",
    "    lines = r.text.splitlines()\n",
    "    \n",
    "    # retrieve the location of columns\n",
    "    name_loc = lines[header_loc].find('Company Name')\n",
    "    type_loc = lines[header_loc].find('Form Type')\n",
    "    cik_loc = lines[header_loc].find('CIK')\n",
    "    date_loc = lines[header_loc].find('Date Filed')\n",
    "    url_loc = lines[header_loc].find('URL')\n",
    "     \n",
    "    # create file name based on the original idx file\n",
    "    file_yr = url.split('/')[-3]\n",
    "    file_qtr = url.split('/')[-2][-1]\n",
    "    file_name = file_yr + \"Q\" + file_qtr + \".csv\"\n",
    "    \n",
    "    # create and write to csv file\n",
    "    with open(file_name, 'w') as wf:\n",
    "        writer = csv.writer(wf, delimiter = ',')\n",
    "        \n",
    "        # go through lines\n",
    "        for line in lines[firstrow_loc:]:\n",
    "            company_name = line[:type_loc].strip()\n",
    "            form_type = line[type_loc:cik_loc].strip()\n",
    "            cik = line[cik_loc:date_loc].strip()\n",
    "            date_filed = line[date_loc:url_loc].strip()\n",
    "            page_url = line[url_loc:].strip()\n",
    "            \n",
    "            # let's foucs on 10-K files only\n",
    "            if form_type == '10-K':\n",
    "            \n",
    "                # create a new row of data using tuple which is ordered and unchanged\n",
    "                row = [company_name, form_type, cik, date_filed, page_url]\n",
    "                writer.writerow(row)\n",
    "                \n",
    "        print(\"{} saved\".format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# change to directory\n",
    "os.chdir(INDEX_DIR)\n",
    "\n",
    "# loop through URLs\n",
    "# for url in getIndexURLs(2016, 2017):\n",
    "for url in demo_index_urls:\n",
    "    writeIndexCSV(url)\n",
    "    time.sleep(3 + random.random() * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 3: Retrieve 10K Filing Information\n",
    "\n",
    "1. Retrieve and save 1 10-K filing using its filing URL\n",
    "2. Parse and save 1 10-K filing's URL and associated meta data\n",
    "3. Read and retrieve 10-K filing page's URL from CSV\n",
    "4. Loop through every CSV and records within a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 3.1 Retrieve 10-K filing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 3.2 Parse 10-K filing's URL and associated meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Parse 10K Form page, including 10-K form URL and other meta data\n",
    "def parseFormPage(url):\n",
    "    '''\n",
    "    Input: URL\n",
    "    \n",
    "    Output:\n",
    "        filer_cik:\n",
    "        filing_date:\n",
    "        report_date:\n",
    "        form_url\n",
    "    '''\n",
    "    \n",
    "    # get page and create soup\n",
    "    res = requests.get(url)\n",
    "    html = res.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # parse filer Info on 10K page\n",
    "    filer_div = soup.find('div', {'id': 'filerDiv'})\n",
    "    filer_text = filer_div.find('span', {'class': 'companyName'}).find('a').get_text()\n",
    "    filer_cik = re.search(r\"(\\d{10})\\s(\\(.+\\))$\" ,filer_text)[1]\n",
    "    \n",
    "    # parse 10K Page Meta data\n",
    "    form_content = soup.find('div', {'class': 'formContent'})\n",
    "    \n",
    "    filing_date = form_content.find('div', text='Filing Date').findNext('div').get_text()\n",
    "    report_date = form_content.find('div', text='Period of Report').findNext('div').get_text()\n",
    "    \n",
    "    # parse 10-K URL\n",
    "    table = soup.find('table', {'class': 'tableFile', 'summary': 'Document Format Files'})\n",
    "    href = table.find('td', text='10-K').find_parent('tr').find('a')['href']\n",
    "    form_url = \"https://www.sec.gov\" + href\n",
    "    \n",
    "    return filer_cik, filing_date, report_date, form_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Testing!!!\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1606163/0001144204-16-089184-index.htm'\n",
    "\n",
    "# in a tuple\n",
    "row = (parseFormPage(url))\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# let's collect form page data to new csv\n",
    "def writeFormPage(file, path):\n",
    "    '''\n",
    "    Input:\n",
    "        Index CSV\n",
    "    Output:\n",
    "        Page CSV\n",
    "    '''\n",
    "    with open(file, 'r') as rf:\n",
    "        reader = csv.reader(rf)\n",
    "        \n",
    "        base_name = os.path.basename(file)\n",
    "        file_path = os.path.join(path, base_name)\n",
    "        \n",
    "        with open(file_path, 'w') as wf:\n",
    "            writer = csv.writer(wf, delimiter = ',')\n",
    "            \n",
    "            for line in reader:\n",
    "                url = line[-1]\n",
    "                page_data = (parseFormPage(url))\n",
    "                writer.writerow(page_data)\n",
    "                \n",
    "                time.sleep(3 + random.random() * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# change to directory\n",
    "os.chdir(PAGE_DIR)\n",
    "\n",
    "# testing!!!\n",
    "writeFormPage(demo_index_csv, PAGE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 3.3 Retrieve 10-K filing page's URL from CSV (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Read CSV into memory using list, ready for processing\n",
    "def readPageURLs(file):\n",
    "    '''\n",
    "    Input: CSV file's full path\n",
    "    \n",
    "    Output:\n",
    "        URLs\n",
    "    '''\n",
    "    with open(file, 'r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        data = [row for row in reader]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# index demo\n",
    "readPageURLs(demo_index_csv)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 3.4 Save 10-K form files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def writeFormHTML(file, path):\n",
    "    '''\n",
    "    Input:\n",
    "        file: Form Page CSV\n",
    "        path: save to\n",
    "    \n",
    "    Output:\n",
    "        Form Document in HTML format\n",
    "    '''\n",
    "    # open csv with info including company CIK and 10-K URLs\n",
    "    with open(file, 'r') as rf:\n",
    "        \n",
    "        reader = csv.reader(rf)\n",
    "        \n",
    "        # be ready to create seperate folers to store raw HTML files\n",
    "        base_name = os.path.basename(file)\n",
    "        base_dir = os.path.splitext(base_name)[0]\n",
    "        dir_path = os.path.join(path, base_dir)\n",
    "        \n",
    "        # create folder if not exists yet\n",
    "        if not os.path.isdir(dir_path):\n",
    "            os.mkdir(dir_path)\n",
    "            \n",
    "        # change to the target directory\n",
    "        os.chdir(dir_path)\n",
    "        \n",
    "        # start to read lines in csv\n",
    "        for line in reader:\n",
    "            \n",
    "            # retrieve info to create file name\n",
    "            company_name = str(line[0])\n",
    "            filing_date = str(line[1])\n",
    "            \n",
    "            file_name = company_name + \"_\" + filing_date + \".html\"\n",
    "            \n",
    "            # get html from SEC using the parsed url\n",
    "            url = str(line[-1])\n",
    "            res = requests.get(url)\n",
    "            html = res.text\n",
    "            time.sleep(3 + random.random() * 3)\n",
    "            \n",
    "            # write to a local file\n",
    "            with open(file_name, 'w') as wf:\n",
    "                wf.write(html)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(FORM_DIR):\n",
    "    os.mkdir(FORM_DIR)\n",
    "os.chdir(FORM_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Testing!\n",
    "file = \"/Users/liang/TextualAnalysis/page/example.csv\"\n",
    "writeFormHTML(file, FORM_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 1: now you need to play with these blocks in class\n",
    "\n",
    "## Feel free to ask questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Homework: spend the weekend to loop through all the CSV files and store all HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Picking up CSV files in a target folder\n",
    "for f_name in os.listdir(INDEX_DIR):\n",
    "    \n",
    "    # only .csv files\n",
    "    if re.search(r'^2\\d{3}Q\\d\\.csv$', f_name):\n",
    "        \n",
    "        # create full path for this file\n",
    "        f_path = os.path.join(INDEX_DIR, f_name)\n",
    "        \n",
    "        # do something\n",
    "        print(f_path)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
